#!/usr/bin/env python3
"""
ê³µê¸‰ì‚¬ ê´€ë¦¬ API ì—”ë“œí¬ì¸íŠ¸
í”„ë¡ íŠ¸ì—”ë“œ ê´€ë¦¬ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ„í•œ RESTful API
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
from datetime import datetime, timedelta
import psycopg2
from psycopg2.extras import RealDictCursor
import json
import logging
import asyncio
import sys
import os

# ìƒìœ„ ë””ë ‰í† ë¦¬ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ê³µê¸‰ì‚¬ ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from supplier.api_integration_manager import APIIntegrationManager, APICredentials
from supplier.scheduler import SupplierCollectionScheduler
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from monitoring.performance_monitor import PerformanceMonitor
from optimization.database_optimizer import DatabaseOptimizer
from optimization.cache_manager import ProductCacheManager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ìƒì„±
app = FastAPI(title="Supplier Management API", version="1.0.0")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],  # Next.js dev server
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²°
def get_db():
    return psycopg2.connect(
        host='localhost',
        port=5434,
        database='yoonni',
        user='postgres',
        password='postgres'
    )

# Pydantic ëª¨ë¸
class CollectionTrigger(BaseModel):
    supplier_name: str
    force: bool = False

class ScheduleUpdate(BaseModel):
    supplier_name: str
    cron_expression: str
    enabled: bool = True

class SupplierStatus(BaseModel):
    id: int
    name: str
    status: str
    last_collection: Optional[datetime]
    next_collection: Optional[datetime]
    total_products: int
    active_products: int
    success_rate: float
    avg_collection_time: float

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
scheduler = None
performance_monitor = None
cache_manager = None

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    global scheduler, performance_monitor, cache_manager
    
    # ìŠ¤ì¼€ì¤„ëŸ¬ ì´ˆê¸°í™”
    scheduler = SupplierCollectionScheduler()
    scheduler.scheduler.start()
    
    # ì„±ëŠ¥ ëª¨ë‹ˆí„° ì´ˆê¸°í™”
    performance_monitor = PerformanceMonitor()
    performance_monitor.start()
    
    # ìºì‹œ ë§¤ë‹ˆì € ì´ˆê¸°í™”
    cache_manager = ProductCacheManager()
    
    logger.info("âœ… Supplier Management API ì‹œì‘ë¨")

@app.on_event("shutdown")
async def shutdown_event():
    """ì„œë²„ ì¢…ë£Œ ì‹œ ì •ë¦¬"""
    global scheduler, performance_monitor
    
    if scheduler:
        scheduler.shutdown()
    
    if performance_monitor:
        performance_monitor.stop()
    
    logger.info("ğŸ›‘ Supplier Management API ì¢…ë£Œë¨")

@app.get("/")
async def root():
    """API ìƒíƒœ í™•ì¸"""
    return {
        "service": "Supplier Management API",
        "status": "running",
        "version": "1.0.0",
        "endpoints": {
            "suppliers": "/api/suppliers",
            "collection_status": "/api/collection/status",
            "collection_logs": "/api/collection/logs",
            "ai_insights": "/api/ai/insights",
            "schedules": "/api/schedules"
        }
    }

@app.get("/api/suppliers", response_model=List[SupplierStatus])
async def get_suppliers():
    """ëª¨ë“  ê³µê¸‰ì‚¬ ìƒíƒœ ì¡°íšŒ"""
    try:
        conn = get_db()
        with conn.cursor(cursor_factory=RealDictCursor) as cursor:
            cursor.execute("""
                SELECT 
                    s.id,
                    s.name,
                    COALESCE(cs.status, 'idle') as status,
                    cs.last_run_at as last_collection,
                    -- ë‹¤ìŒ ì‹¤í–‰ ì‹œê°„ ê³„ì‚° (ê°„ë‹¨íˆ 24ì‹œê°„ í›„ë¡œ ê°€ì •)
                    CASE 
                        WHEN cs.last_run_at IS NOT NULL 
                        THEN cs.last_run_at + INTERVAL '24 hours'
                        ELSE NULL
                    END as next_collection,
                    COUNT(sp.id) as total_products,
                    COUNT(CASE WHEN sp.status = 'active' THEN 1 END) as active_products,
                    COALESCE(stats.success_rate, 0) as success_rate,
                    COALESCE(stats.avg_duration_seconds, 0) as avg_collection_time
                FROM suppliers s
                LEFT JOIN supplier_collection_status cs ON s.id = cs.supplier_id
                LEFT JOIN supplier_products sp ON s.id = sp.supplier_id
                LEFT JOIN supplier_collection_stats stats ON s.name = stats.supplier_name
                WHERE s.is_active = true
                GROUP BY s.id, s.name, cs.status, cs.last_run_at, 
                         stats.success_rate, stats.avg_duration_seconds
                ORDER BY s.name
            """)
            
            suppliers = cursor.fetchall()
            return suppliers
            
    except Exception as e:
        logger.error(f"ê³µê¸‰ì‚¬ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        conn.close()

@app.get("/api/collection/status")
async def get_collection_status():
    """í˜„ì¬ ìˆ˜ì§‘ ìƒíƒœ ì¡°íšŒ"""
    try:
        conn = get_db()
        with conn.cursor(cursor_factory=RealDictCursor) as cursor:
            # í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì‘ì—…
            cursor.execute("""
                SELECT 
                    cs.id,
                    s.name as supplier_name,
                    cs.status,
                    cs.started_at,
                    cs.last_run_at,
                    cs.error_message,
                    EXTRACT(EPOCH FROM (NOW() - cs.started_at))::int as duration_seconds
                FROM supplier_collection_status cs
                JOIN suppliers s ON cs.supplier_id = s.id
                WHERE cs.status = 'running'
                ORDER BY cs.started_at DESC
            """)
            
            running_jobs = cursor.fetchall()
            
            # ìµœê·¼ ì™„ë£Œëœ ì‘ì—…
            cursor.execute("""
                SELECT 
                    h.id,
                    h.supplier_name,
                    h.status,
                    h.started_at,
                    h.completed_at,
                    h.duration_seconds,
                    h.collected_count,
                    h.failed_count,
                    h.error_details
                FROM scheduler_execution_history h
                WHERE h.completed_at > NOW() - INTERVAL '24 hours'
                ORDER BY h.completed_at DESC
                LIMIT 10
            """)
            
            recent_jobs = cursor.fetchall()
            
            return {
                "running_jobs": running_jobs,
                "recent_jobs": recent_jobs,
                "scheduler_status": "running" if scheduler and scheduler.scheduler.running else "stopped"
            }
            
    except Exception as e:
        logger.error(f"ìˆ˜ì§‘ ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        conn.close()

@app.get("/api/collection/logs")
async def get_collection_logs(
    supplier_name: Optional[str] = None,
    days: int = 7,
    limit: int = 100
):
    """ìˆ˜ì§‘ ë¡œê·¸ ì¡°íšŒ"""
    try:
        conn = get_db()
        with conn.cursor(cursor_factory=RealDictCursor) as cursor:
            query = """
                SELECT 
                    l.id,
                    s.name as supplier_name,
                    l.status,
                    l.started_at,
                    l.completed_at,
                    l.collected_count,
                    l.failed_count,
                    l.error_count,
                    l.processing_time_seconds,
                    l.error_details
                FROM supplier_collection_logs l
                JOIN suppliers s ON l.supplier_id = s.id
                WHERE l.started_at > NOW() - INTERVAL '%s days'
            """
            
            params = [days]
            
            if supplier_name:
                query += " AND s.name = %s"
                params.append(supplier_name)
            
            query += " ORDER BY l.started_at DESC LIMIT %s"
            params.append(limit)
            
            cursor.execute(query, params)
            logs = cursor.fetchall()
            
            return logs
            
    except Exception as e:
        logger.error(f"ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        conn.close()

@app.post("/api/collection/trigger")
async def trigger_collection(
    trigger: CollectionTrigger,
    background_tasks: BackgroundTasks
):
    """ìˆ˜ë™ ìˆ˜ì§‘ íŠ¸ë¦¬ê±°"""
    try:
        # ì¤‘ë³µ ì‹¤í–‰ í™•ì¸
        if not trigger.force:
            conn = get_db()
            with conn.cursor() as cursor:
                cursor.execute("""
                    SELECT status FROM supplier_collection_status cs
                    JOIN suppliers s ON cs.supplier_id = s.id
                    WHERE s.name = %s AND cs.status = 'running'
                """, (trigger.supplier_name,))
                
                if cursor.fetchone():
                    conn.close()
                    raise HTTPException(
                        status_code=409,
                        detail=f"{trigger.supplier_name} ìˆ˜ì§‘ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤"
                    )
            conn.close()
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìˆ˜ì§‘ ì‹¤í–‰
        background_tasks.add_task(
            run_collection_task,
            trigger.supplier_name
        )
        
        return {
            "status": "triggered",
            "supplier": trigger.supplier_name,
            "message": f"{trigger.supplier_name} ìˆ˜ì§‘ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤"
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ìˆ˜ì§‘ íŠ¸ë¦¬ê±° ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/ai/insights")
async def get_ai_insights(
    supplier_name: Optional[str] = None,
    category: Optional[str] = None,
    limit: int = 20
):
    """AI ë¶„ì„ ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ"""
    try:
        conn = get_db()
        with conn.cursor(cursor_factory=RealDictCursor) as cursor:
            query = """
                SELECT 
                    pai.*,
                    CAST(pai.predicted_price AS FLOAT) - sp.price as price_diff,
                    CASE 
                        WHEN CAST(pai.demand_grade AS CHAR) IN ('A', 'B') THEN 'high'
                        WHEN CAST(pai.demand_grade AS CHAR) = 'C' THEN 'medium'
                        ELSE 'low'
                    END as demand_level_group
                FROM product_ai_insights pai
                JOIN supplier_products sp ON pai.product_id = sp.id
                WHERE 1=1
            """
            
            params = []
            
            if supplier_name:
                query += " AND pai.supplier_name = %s"
                params.append(supplier_name)
            
            if category:
                query += " AND pai.category = %s"
                params.append(category)
            
            query += """ 
                ORDER BY 
                    CAST(pai.demand_score AS FLOAT) DESC,
                    ABS(CAST(pai.predicted_price AS FLOAT) - sp.price) DESC
                LIMIT %s
            """
            params.append(limit)
            
            cursor.execute(query, params)
            insights = cursor.fetchall()
            
            # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
            cursor.execute("""
                SELECT * FROM category_ai_insights
                ORDER BY avg_demand_score DESC
                LIMIT 10
            """)
            
            category_stats = cursor.fetchall()
            
            return {
                "product_insights": insights,
                "category_stats": category_stats
            }
            
    except Exception as e:
        logger.error(f"AI ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        conn.close()

@app.get("/api/schedules")
async def get_schedules():
    """ìŠ¤ì¼€ì¤„ ì„¤ì • ì¡°íšŒ"""
    try:
        if not scheduler:
            raise HTTPException(status_code=503, detail="ìŠ¤ì¼€ì¤„ëŸ¬ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        
        jobs = []
        for job in scheduler.scheduler.get_jobs():
            jobs.append({
                "id": job.id,
                "name": job.name,
                "next_run_time": job.next_run_time,
                "trigger": str(job.trigger),
                "args": job.args,
                "kwargs": job.kwargs
            })
        
        return {
            "scheduler_running": scheduler.scheduler.running,
            "jobs": jobs
        }
        
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.put("/api/schedules")
async def update_schedule(schedule: ScheduleUpdate):
    """ìŠ¤ì¼€ì¤„ ì„¤ì • ì—…ë°ì´íŠ¸"""
    try:
        conn = get_db()
        with conn.cursor() as cursor:
            # supplier_configs ì—…ë°ì´íŠ¸
            cursor.execute("""
                UPDATE supplier_configs 
                SET settings = settings || jsonb_build_object(
                    'collection_schedule', %s,
                    'collection_enabled', %s
                )
                WHERE supplier_id = (
                    SELECT id FROM suppliers WHERE name = %s
                )
            """, (schedule.cron_expression, schedule.enabled, schedule.supplier_name))
            
            conn.commit()
        
        # ìŠ¤ì¼€ì¤„ëŸ¬ ì¬ì‹œì‘
        if scheduler:
            scheduler.reload_schedules()
        
        return {
            "status": "updated",
            "supplier": schedule.supplier_name,
            "cron": schedule.cron_expression,
            "enabled": schedule.enabled
        }
        
    except Exception as e:
        logger.error(f"ìŠ¤ì¼€ì¤„ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        conn.close()

@app.get("/api/dashboard/stats")
async def get_dashboard_stats():
    """ëŒ€ì‹œë³´ë“œ í†µê³„"""
    try:
        conn = get_db()
        with conn.cursor(cursor_factory=RealDictCursor) as cursor:
            # ì „ì²´ í†µê³„
            cursor.execute("""
                SELECT 
                    COUNT(DISTINCT s.id) as total_suppliers,
                    COUNT(DISTINCT sp.id) as total_products,
                    COUNT(DISTINCT CASE WHEN sp.status = 'active' THEN sp.id END) as active_products,
                    COUNT(DISTINCT CASE WHEN spa.id IS NOT NULL THEN sp.id END) as analyzed_products,
                    AVG(CASE WHEN spa.analysis_result->>'demand_score' IS NOT NULL 
                        THEN CAST(spa.analysis_result->>'demand_score' AS FLOAT) END) as avg_demand_score
                FROM suppliers s
                LEFT JOIN supplier_products sp ON s.id = sp.supplier_id
                LEFT JOIN supplier_product_analysis spa ON sp.id = spa.product_id
                WHERE s.is_active = true
            """)
            
            overall_stats = cursor.fetchone()
            
            # ìµœê·¼ 24ì‹œê°„ ìˆ˜ì§‘ í†µê³„
            cursor.execute("""
                SELECT 
                    COUNT(*) as collections_24h,
                    SUM(collected_count) as products_collected_24h,
                    AVG(processing_time_seconds) as avg_processing_time,
                    COUNT(CASE WHEN status = 'completed' THEN 1 END) as successful_collections
                FROM supplier_collection_logs
                WHERE started_at > NOW() - INTERVAL '24 hours'
            """)
            
            recent_stats = cursor.fetchone()
            
            return {
                "overall": overall_stats,
                "recent_24h": recent_stats,
                "timestamp": datetime.now().isoformat()
            }
            
    except Exception as e:
        logger.error(f"ëŒ€ì‹œë³´ë“œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    finally:
        conn.close()

# ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ í•¨ìˆ˜
async def run_collection_task(supplier_name: str):
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ ìˆ˜ì§‘ ì‹¤í–‰"""
    try:
        logger.info(f"ğŸš€ {supplier_name} ìˆ˜ì§‘ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)")
        
        # APIIntegrationManagerë¥¼ ì‚¬ìš©í•˜ì—¬ ìˆ˜ì§‘
        manager = APIIntegrationManager()
        
        if supplier_name.lower() == 'all':
            results = await manager.collect_all_suppliers()
        else:
            # ê°œë³„ ê³µê¸‰ì‚¬ ìˆ˜ì§‘
            conn = get_db()
            with conn.cursor(cursor_factory=RealDictCursor) as cursor:
                cursor.execute("""
                    SELECT 
                        sc.supplier_id,
                        sc.api_endpoint,
                        sc.auth_type,
                        sc.credentials,
                        sc.settings
                    FROM supplier_configs sc
                    JOIN suppliers s ON sc.supplier_id = s.id
                    WHERE s.name = %s AND s.is_active = true
                """, (supplier_name,))
                
                config = cursor.fetchone()
                conn.close()
                
                if not config:
                    raise ValueError(f"ê³µê¸‰ì‚¬ ì„¤ì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {supplier_name}")
                
                credentials = APICredentials(
                    api_key=config['credentials'].get('api_key'),
                    api_secret=config['credentials'].get('api_secret'),
                    vendor_id=config['credentials'].get('vendor_id'),
                    username=config['credentials'].get('username'),
                    password=config['credentials'].get('password')
                )
                
                if supplier_name == 'ì˜¤ë„ˆí´ëœ':
                    result = await manager.collect_ownerclan_products(credentials)
                elif supplier_name == 'ì  íŠ¸ë ˆì´ë“œ':
                    result = await manager.collect_zentrade_products(credentials)
                else:
                    raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ê³µê¸‰ì‚¬: {supplier_name}")
                
                results = {supplier_name: result}
        
        logger.info(f"âœ… {supplier_name} ìˆ˜ì§‘ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"âŒ {supplier_name} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")

@app.get("/api/performance/metrics")
async def get_performance_metrics():
    """ì‹¤ì‹œê°„ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    try:
        if not performance_monitor:
            raise HTTPException(status_code=503, detail="ì„±ëŠ¥ ëª¨ë‹ˆí„°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        
        metrics = performance_monitor.get_realtime_metrics()
        analysis = performance_monitor.analyze_performance()
        
        return {
            "metrics": metrics,
            "analysis": analysis,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/performance/optimization")
async def get_optimization_report():
    """ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™” ë³´ê³ ì„œ"""
    try:
        optimizer = DatabaseOptimizer()
        report = optimizer.get_optimization_report()
        
        return report
        
    except Exception as e:
        logger.error(f"ìµœì í™” ë³´ê³ ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/performance/optimize")
async def run_optimization(
    optimization_type: str = "index"  # index, vacuum, analyze
):
    """ìµœì í™” ì‹¤í–‰"""
    try:
        optimizer = DatabaseOptimizer()
        
        if optimization_type == "index":
            optimizer.optimize_indexes()
            message = "ì¸ë±ìŠ¤ ìµœì í™” ì™„ë£Œ"
        elif optimization_type == "vacuum":
            optimizer.vacuum_and_analyze()
            message = "VACUUM ë° ANALYZE ì™„ë£Œ"
        elif optimization_type == "analyze":
            slow_queries = optimizer.analyze_slow_queries()
            message = f"ëŠë¦° ì¿¼ë¦¬ {len(slow_queries)}ê°œ ë¶„ì„ ì™„ë£Œ"
        else:
            raise HTTPException(status_code=400, detail="ì˜ëª»ëœ ìµœì í™” íƒ€ì…")
        
        return {
            "status": "completed",
            "type": optimization_type,
            "message": message,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ìµœì í™” ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/cache/stats")
async def get_cache_stats():
    """ìºì‹œ í†µê³„ ì¡°íšŒ"""
    try:
        if not cache_manager:
            raise HTTPException(status_code=503, detail="ìºì‹œ ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        
        stats = cache_manager.get_stats()
        
        return {
            "cache_stats": stats,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ìºì‹œ í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/cache/invalidate")
async def invalidate_cache(
    namespace: Optional[str] = None,
    supplier_id: Optional[int] = None
):
    """ìºì‹œ ë¬´íš¨í™”"""
    try:
        if not cache_manager:
            raise HTTPException(status_code=503, detail="ìºì‹œ ë§¤ë‹ˆì €ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
        
        invalidated = 0
        
        if namespace:
            invalidated = cache_manager.invalidate_namespace(namespace)
        elif supplier_id:
            invalidated = cache_manager.invalidate_supplier_cache(supplier_id)
        else:
            raise HTTPException(status_code=400, detail="namespace ë˜ëŠ” supplier_id í•„ìš”")
        
        return {
            "status": "invalidated",
            "count": invalidated,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"ìºì‹œ ë¬´íš¨í™” ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8004)